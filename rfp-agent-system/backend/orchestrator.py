"""Orchestrator - Coordinates all RFP analysis agents"""
import os
from memory.short_term_memory import ShortTermMemory
from agents.introduction_agent import IntroductionAgent
from agents.business_process_agent import BusinessProcessAgent
from agents.gap_agent import GapAgent
from agents.persona_agent import PersonaAgent
from agents.pain_point_agent import PainPointsAgent
from agents.impact_agent import ImpactfulStatementsAgent
from agents.challenge_agent import ChallengesAgent
from agents.functional_requirements_agent import FunctionalRequirementsAgent
from agents.nfr_agent import NFRAgent
from agents.architect_agent import ArchitectAgent
from agents.constraints_agent import ConstraintsAgent
from agents.assumptions_agent import AssumptionsAgent
from llm_client import local_llm


# Configuration
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROMPTS_DIR = os.path.join(BASE_DIR, "prompts")
LLM = local_llm

def run_all_agents(text: str) -> dict:
    """
    Run all 12 RFP analysis agents on the given text.
    
    Args:
        text: RFP document text to analyze
        
    Returns:
        dict: All agent outputs {agent_name: analysis_result}
    """
    memory = ShortTermMemory()

    # Initialize all agents with prompts
    agents = {
        "introduction": IntroductionAgent(LLM, open(os.path.join(PROMPTS_DIR, "introduction.txt")).read()),
        "challenges": ChallengesAgent(LLM, open(os.path.join(PROMPTS_DIR, "challenges.txt")).read()),
        "pain_points": PainPointsAgent(LLM, open(os.path.join(PROMPTS_DIR, "pain_points.txt")).read()),
        "business_process": BusinessProcessAgent(LLM, open(os.path.join(PROMPTS_DIR, "business_process.txt")).read()),
        "gap": GapAgent(LLM, open(os.path.join(PROMPTS_DIR, "gap.txt")).read()),
        "personas": PersonaAgent(LLM, open(os.path.join(PROMPTS_DIR, "persona.txt")).read()),
        "constraints": ConstraintsAgent(LLM, open(os.path.join(PROMPTS_DIR, "constraints.txt")).read()),
        "functional_requirements": FunctionalRequirementsAgent(LLM, open(os.path.join(PROMPTS_DIR, "functional_requirements.txt")).read()),
        "nfr": NFRAgent(LLM, open(os.path.join(PROMPTS_DIR, "nfr.txt")).read()),
        "architecture": ArchitectAgent(LLM, open(os.path.join(PROMPTS_DIR, "architect.txt")).read()),
        "assumptions": AssumptionsAgent(LLM, open(os.path.join(PROMPTS_DIR, "assumptions.txt")).read()),
        "impact": ImpactfulStatementsAgent(LLM, open(os.path.join(PROMPTS_DIR, "impact.txt")).read()),
    }

    # Run each agent
    for name, agent in agents.items():
        print(f"  • Running {name} agent...")
        output = agent.extract(text)
        memory.add(name, output)

    return memory.get_all()


def save_to_kb(memory_output: dict, output_file: str = "kb.md"):
    """
    Save agent analysis results to structured knowledge base file.
    
    Args:
        memory_output: Dict of agent results
        output_file: Output filename (default: kb.md)
    """
    with open(output_file, "w", encoding="utf-8") as f:
        # Header
        f.write("# Knowledge Base for RFP Analysis\n\n")
        f.write("*Generated by RFP Process Enhancer - AI Agent System*\n\n")
        f.write("---\n\n")
        
        # 1. Introduction (from introduction agent)
        if "introduction" in memory_output:
            f.write(memory_output["introduction"] + "\n\n")
            f.write("---\n\n")
        
        # 2. Requirements Section
        f.write("## 2. Requirements\n\n")
        
        # 2.1 Challenges
        if "challenges" in memory_output:
            f.write(memory_output["challenges"] + "\n\n")
        
        # 2.2 User Pain Points
        if "pain_points" in memory_output:
            f.write(memory_output["pain_points"] + "\n\n")
        
        # 2.3 Current Business Process
        if "business_process" in memory_output:
            f.write(memory_output["business_process"] + "\n\n")
        
        # 2.4 Gap Analysis
        if "gap" in memory_output:
            f.write(memory_output["gap"] + "\n\n")
        
        # 2.5 Personas
        if "personas" in memory_output:
            f.write(memory_output["personas"] + "\n\n")
        
        # 2.6 Constraints
        if "constraints" in memory_output:
            f.write(memory_output["constraints"] + "\n\n")
        
        # 2.7 Functional Requirements
        if "functional_requirements" in memory_output:
            f.write(memory_output["functional_requirements"] + "\n\n")
        
        # 2.8 Non-Functional Requirements
        if "nfr" in memory_output:
            f.write(memory_output["nfr"] + "\n\n")
        
        f.write("---\n\n")
        
        # 3. Solutioning Section
        f.write("## 3. Solutioning\n\n")
        
        # 3.1 Architecture (comprehensive from architect agent)
        if "architecture" in memory_output:
            f.write(memory_output["architecture"] + "\n\n")
        
        f.write("---\n\n")
        
        # 4. Assumptions and Dependencies
        if "assumptions" in memory_output:
            f.write(memory_output["assumptions"] + "\n\n")
        
        f.write("---\n\n")
        
        # Appendix: Impact Statements (supporting information)
        if "impact" in memory_output:
            f.write("## Appendix: Impactful Business Statements\n\n")
            f.write("*This section contains key metrics, compliance requirements, and strategic statements extracted from the RFP.*\n\n")
            f.write(memory_output["impact"] + "\n\n")


if __name__ == "__main__":
    # Test with sample text
    text = open("data/chunks/chunk_1.txt").read()
    results = run_all_agents(text)
    
    print("=== All Agent Results ===")
    for agent_name, output in results.items():
        print(f"\n--- {agent_name.upper()} ---")
        print(output)
    
    # Save to knowledge base
    save_to_kb(results)
    print("\n✓ Results saved to kb.md")
