"""Orchestrator - Coordinates all RFP analysis agents"""
import os
from memory.short_term_memory import ShortTermMemory
from agents.business_process_agent import BusinessProcessAgent
from agents.gap_agent import GapAgent
from agents.persona_agent import PersonaAgent
from agents.pain_point_agent import PainPointsAgent
from agents.impact_agent import ImpactfulStatementsAgent
from agents.challenge_agent import ChallengesAgent
from agents.nfr_agent import NFRAgent
from agents.architect_agent import ArchitectAgent
from agents.constraints_agent import ConstraintsAgent
from agents.assumptions_agent import AssumptionsAgent
from llm_client import local_llm


# Configuration
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROMPTS_DIR = os.path.join(BASE_DIR, "prompts")
LLM = local_llm

def run_all_agents(text: str) -> dict:
    """
    Run all 10 RFP analysis agents on the given text.
    
    Args:
        text: RFP document text to analyze
        
    Returns:
        dict: All agent outputs {agent_name: analysis_result}
    """
    memory = ShortTermMemory()

    # Initialize all agents with prompts
    agents = {
        "business_process": BusinessProcessAgent(LLM, open(os.path.join(PROMPTS_DIR, "business_process.txt")).read()),
        "gap": GapAgent(LLM, open(os.path.join(PROMPTS_DIR, "gap.txt")).read()),
        "personas": PersonaAgent(LLM, open(os.path.join(PROMPTS_DIR, "persona.txt")).read()),
        "pain_points": PainPointsAgent(LLM, open(os.path.join(PROMPTS_DIR, "pain_points.txt")).read()),
        "impact": ImpactfulStatementsAgent(LLM, open(os.path.join(PROMPTS_DIR, "impact.txt")).read()),
        "challenges": ChallengesAgent(LLM, open(os.path.join(PROMPTS_DIR, "challenges.txt")).read()),
        "nfr": NFRAgent(LLM, open(os.path.join(PROMPTS_DIR, "nfr.txt")).read()),
        "architecture": ArchitectAgent(LLM, open(os.path.join(PROMPTS_DIR, "architect.txt")).read()),
        "constraints": ConstraintsAgent(LLM, open(os.path.join(PROMPTS_DIR, "constraints.txt")).read()),
        "assumptions": AssumptionsAgent(LLM, open(os.path.join(PROMPTS_DIR, "assumptions.txt")).read()),
    }

    # Run each agent
    for name, agent in agents.items():
        print(f"  • Running {name} agent...")
        output = agent.extract(text)
        memory.add(name, output)

    return memory.get_all()


def save_to_kb(memory_output: dict, output_file: str = "kb.md"):
    """
    Save agent analysis results to knowledge base file.
    
    Args:
        memory_output: Dict of agent results
        output_file: Output filename (default: kb.md)
    """
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("# RFP Analysis Knowledge Base\n\n")
        f.write("Generated by RFP Process Enhancer - AI Agent System\n\n")
        f.write("---\n\n")
        
        for key, value in memory_output.items():
            f.write(f"## {key.upper().replace('_', ' ')}\n\n")
            f.write(value + "\n\n")
            f.write("---\n\n")


if __name__ == "__main__":
    # Test with sample text
    text = open("data/chunks/chunk_1.txt").read()
    results = run_all_agents(text)
    
    print("=== All Agent Results ===")
    for agent_name, output in results.items():
        print(f"\n--- {agent_name.upper()} ---")
        print(output)
    
    # Save to knowledge base
    save_to_kb(results)
    print("\n✓ Results saved to kb.md")
